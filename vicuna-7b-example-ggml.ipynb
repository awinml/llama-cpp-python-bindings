{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install llama-cpp-python","metadata":{"execution":{"iopub.status.busy":"2023-06-30T19:52:18.244198Z","iopub.execute_input":"2023-06-30T19:52:18.244712Z","iopub.status.idle":"2023-06-30T19:53:11.485470Z","shell.execute_reply.started":"2023-06-30T19:52:18.244672Z","shell.execute_reply":"2023-06-30T19:53:11.484285Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting llama-cpp-python\n  Downloading llama_cpp_python-0.1.67.tar.gz (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (4.5.0)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (1.23.5)\nCollecting diskcache>=5.6.1 (from llama-cpp-python)\n  Downloading diskcache-5.6.1-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.67-cp310-cp310-linux_x86_64.whl size=266388 sha256=7a7e298de348d81b1064e979e30ff08ff97a2efead27a16f4156b17cdb96eb1c\n  Stored in directory: /root/.cache/pip/wheels/b9/1c/63/394761fe4b898ac1090c6d2211588e88b71ab64db6e1d950af\nSuccessfully built llama-cpp-python\nInstalling collected packages: diskcache, llama-cpp-python\nSuccessfully installed diskcache-5.6.1 llama-cpp-python-0.1.67\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport urllib.request\n\n\ndef download_file(file_link, filename):\n    # Checks if the file already exists before downloading\n    if not os.path.isfile(filename):\n        urllib.request.urlretrieve(file_link, filename)\n        print(\"File downloaded successfully.\")\n    else:\n        print(\"File already exists.\")\n\n# Dowloading GGML model from HuggingFace\nggml_model_path = \"https://huggingface.co/CRD716/ggml-vicuna-1.1-quantized/resolve/main/ggml-vicuna-7b-1.1-q4_1.bin\"\nfilename = \"ggml-vicuna-7b-1.1-q4_1.bin\"\n\ndownload_file(ggml_model_path, filename)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-30T19:53:11.487727Z","iopub.execute_input":"2023-06-30T19:53:11.488112Z","iopub.status.idle":"2023-06-30T19:54:32.558378Z","shell.execute_reply.started":"2023-06-30T19:53:11.488062Z","shell.execute_reply":"2023-06-30T19:54:32.557149Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"File downloaded successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"from llama_cpp import Llama\n\nllm = Llama(model_path=\"ggml-vicuna-7b-1.1-q4_1.bin\", n_ctx=512, n_batch=126)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T19:54:32.560141Z","iopub.execute_input":"2023-06-30T19:54:32.560505Z","iopub.status.idle":"2023-06-30T19:54:32.871479Z","shell.execute_reply.started":"2023-06-30T19:54:32.560476Z","shell.execute_reply":"2023-06-30T19:54:32.870358Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"llama.cpp: loading model from ggml-vicuna-7b-1.1-q4_1.bin\nllama_model_load_internal: format     = ggjt v3 (latest)\nllama_model_load_internal: n_vocab    = 32000\nllama_model_load_internal: n_ctx      = 512\nllama_model_load_internal: n_embd     = 4096\nllama_model_load_internal: n_mult     = 256\nllama_model_load_internal: n_head     = 32\nllama_model_load_internal: n_layer    = 32\nllama_model_load_internal: n_rot      = 128\nllama_model_load_internal: ftype      = 3 (mostly Q4_1)\nllama_model_load_internal: n_ff       = 11008\nllama_model_load_internal: n_parts    = 1\nllama_model_load_internal: model size = 7B\nllama_model_load_internal: ggml ctx size =    0.07 MB\nllama_model_load_internal: mem required  = 5809.34 MB (+ 1026.00 MB per state)\nllama_new_context_with_model: kv self size  =  256.00 MB\nAVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n","output_type":"stream"}]},{"cell_type":"code","source":"def generate_text(\n    prompt=\"Who is the CEO of Apple?\",\n    max_tokens=256,\n    temperature=0.1,\n    top_p=0.5,\n    echo=False,\n    stop=[\"#\"],\n):\n    output = llm(\n        prompt,\n        max_tokens=max_tokens,\n        temperature=temperature,\n        top_p=top_p,\n        echo=echo,\n        stop=stop,\n    )\n    output_text = output[\"choices\"][0][\"text\"].strip()\n    return output_text","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:03:54.763163Z","iopub.execute_input":"2023-06-30T20:03:54.763575Z","iopub.status.idle":"2023-06-30T20:03:54.770224Z","shell.execute_reply.started":"2023-06-30T20:03:54.763544Z","shell.execute_reply":"2023-06-30T20:03:54.769458Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"generate_text()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T19:54:33.025102Z","iopub.execute_input":"2023-06-30T19:54:33.025532Z","iopub.status.idle":"2023-06-30T19:54:44.876036Z","shell.execute_reply.started":"2023-06-30T19:54:33.025491Z","shell.execute_reply":"2023-06-30T19:54:44.874894Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"\nllama_print_timings:        load time =  3212.62 ms\nllama_print_timings:      sample time =    12.38 ms /    19 runs   (    0.65 ms per token,  1535.35 tokens per second)\nllama_print_timings: prompt eval time =  3212.51 ms /     9 tokens (  356.95 ms per token,     2.80 tokens per second)\nllama_print_timings:        eval time =  8518.56 ms /    18 runs   (  473.25 ms per token,     2.11 tokens per second)\nllama_print_timings:       total time = 11835.81 ms\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'As of 2021, the CEO of Apple is Tim Cook.'"},"metadata":{}}]},{"cell_type":"code","source":"generate_text(\"Compose an engaging travel blog post about a recent trip to Hawaii, highlighting cultural experiences and must-see attractions.\", max_tokens=356)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:03:59.342240Z","iopub.execute_input":"2023-06-30T20:03:59.342646Z","iopub.status.idle":"2023-06-30T20:06:55.482151Z","shell.execute_reply.started":"2023-06-30T20:03:59.342616Z","shell.execute_reply":"2023-06-30T20:06:55.481009Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Llama.generate: prefix-match hit\n\nllama_print_timings:        load time =  3212.62 ms\nllama_print_timings:      sample time =   227.04 ms /   356 runs   (    0.64 ms per token,  1568.01 tokens per second)\nllama_print_timings: prompt eval time =  9350.52 ms /    27 tokens (  346.32 ms per token,     2.89 tokens per second)\nllama_print_timings:        eval time = 164856.95 ms /   355 runs   (  464.39 ms per token,     2.15 tokens per second)\nllama_print_timings:       total time = 176131.01 ms\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"\"Hawaii is a state located in the United States of America that is known for its beautiful beaches, lush landscapes, and rich culture. It is made up of six islands: Oahu, Maui, Kauai, Lanai, Molokai, and Hawaii (also known as the Big Island). Each island has its own unique attractions and experiences to offer visitors.\\nOne of the most interesting cultural experiences in Hawaii is visiting a traditional Hawaiian village or ahupuaa. An ahupuaa is a system of land use that was used by ancient Hawaiians to manage their resources sustainably. It consists of a coastal area, a freshwater stream, and the surrounding uplands and forests. Visitors can learn about this traditional way of life at the Polynesian Cultural Center in Oahu or by visiting a traditional Hawaiian village on one of the other islands.\\nAnother must-see attraction in Hawaii is the Pearl Harbor Memorial. This historic site commemorates the attack on Pearl Harbor on December 7, 1941, which led to the United States' entry into World War II. Visitors can see the USS Arizona Memorial, a memorial that sits above the sunken battleship USS Arizona and provides an overview of the attack. They can also visit other museums and exhibits on the site to learn more about this important event in American history.\\nHawaii is also known for its beautiful beaches and crystal clear waters, which are perfect for swimming, snorkeling, and sunbathing. Some of the most popular beaches include Waikiki Beach\""},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}